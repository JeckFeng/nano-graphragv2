# LLM 配置文件
# 
# 本配置文件定义了多智能体系统使用的大语言模型配置
# 支持的提供商: openai, deepseek, dashscope
#
# 配置说明:
#   - provider: LLM 提供商 (openai/deepseek/dashscope)
#   - model_name: 模型名称
#   - temperature: 温度参数 (0.0-2.0)，控制输出随机性
#   - max_tokens: 最大输出 token 数（可选）
#   - timeout: 请求超时时间（秒）

# 默认 LLM 配置
default:
  provider: deepseek
  model_name: deepseek-chat
  temperature: 0.7
  max_tokens: null
  timeout: 60.0

# OpenAI 配置
openai:
  provider: openai
  model_name: gpt-4o
  temperature: 0.7
  max_tokens: null
  timeout: 60.0
  # API Key 和 Base URL 从环境变量读取:
  # - OPENAI_API_KEY
  # - OPENAI_BASE_URL (可选)

# DeepSeek 配置
deepseek:
  provider: deepseek
  model_name: deepseek-chat
  temperature: 0.7
  max_tokens: null
  timeout: 60.0
  # API Key 和 Base URL 从环境变量读取:
  # - DEEPSEEK_API_KEY
  # - DEEPSEEK_BASE_URL (可选)

# DashScope (阿里通义千问) 配置
dashscope:
  provider: dashscope
  model_name: qwen-plus
  temperature: 0.7
  max_tokens: null
  timeout: 60.0
  # API Key 和 Base URL 从环境变量读取:
  # - DASHSCOPE_API_KEY
  # - DASHSCOPE_BASE_URL (可选)

# 支持的模型列表
supported_models:
  openai:
    - gpt-4o
    - gpt-4o-mini
    - gpt-4-turbo
    - gpt-3.5-turbo
  deepseek:
    - deepseek-chat
    - deepseek-coder
  dashscope:
    - qwen-max
    - qwen-plus
